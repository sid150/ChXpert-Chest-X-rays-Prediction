{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f03444e-8ebb-478e-9dc9-3c17c95f18c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from torchinfo import summary\n",
    "import time\n",
    "import numpy as np\n",
    "from model_def import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54c7cb81-b6be-4ac9-a463-d4641b860c13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "======================================================================\n",
       "Layer (type:depth-idx)                        Param #\n",
       "======================================================================\n",
       "LightningCheXpertModel                        --\n",
       "├─DenseNet: 1-1                               --\n",
       "│    └─Sequential: 2-1                        --\n",
       "│    │    └─Conv2d: 3-1                       9,408\n",
       "│    │    └─BatchNorm2d: 3-2                  128\n",
       "│    │    └─ReLU: 3-3                         --\n",
       "│    │    └─MaxPool2d: 3-4                    --\n",
       "│    │    └─_DenseBlock: 3-5                  335,040\n",
       "│    │    └─_Transition: 3-6                  33,280\n",
       "│    │    └─_DenseBlock: 3-7                  919,680\n",
       "│    │    └─_Transition: 3-8                  132,096\n",
       "│    │    └─_DenseBlock: 3-9                  2,837,760\n",
       "│    │    └─_Transition: 3-10                 526,336\n",
       "│    │    └─_DenseBlock: 3-11                 2,158,080\n",
       "│    │    └─BatchNorm2d: 3-12                 2,048\n",
       "│    └─Linear: 2-2                            14,350\n",
       "├─BCEWithLogitsLoss: 1-2                      --\n",
       "======================================================================\n",
       "Total params: 6,968,206\n",
       "Trainable params: 6,968,206\n",
       "Non-trainable params: 0\n",
       "======================================================================"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = r\"./mlflowModel1.pt\"  \n",
    "device = torch.device(\"cpu\")\n",
    "model = torch.load(model_path, map_location=device, weights_only=False)\n",
    "model.eval()  \n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "de1d7fcf-22e6-4d76-a461-2d5ac1cefe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheXpertDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, csv_path, image_size=224):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.image_paths = self.df[\"corrected_path\"].values\n",
    "\n",
    "        # Extract label columns from start to end\n",
    "        start_col = \"Enlarged Cardiomediastinum\"\n",
    "        end_col = \"No Finding\"\n",
    "        label_columns = self.df.loc[:, start_col:end_col].columns\n",
    "\n",
    "        # Load and convert -1 to 1\n",
    "        self.labels = self.df[label_columns].astype(np.float32).values\n",
    "        self.labels[self.labels == -1.0] = 1.0  # Convert -1s to 1s\n",
    "\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((image_size, image_size)),\n",
    "            transforms.Grayscale(num_output_channels=3),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "        ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # path = self.image_paths[idx].replace(\"/data/\", \"/\")\n",
    "        path = self.image_paths[idx].replace(\"/mnt/data/\", \"/mnt/dataset/\")\n",
    "        image = Image.open(path).convert(\"RGB\")\n",
    "        image = self.transform(image)\n",
    "        label = torch.tensor(self.labels[idx], dtype=torch.float32)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1070bfdd-7af4-42aa-8938-47ee75c882b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Subset, random_split\n",
    "\n",
    "csv_path = r\"filtered_chexpert_paths.csv\"\n",
    "\n",
    "full_dataset = CheXpertDataset(csv_path)\n",
    "total_len = len(full_dataset)\n",
    "\n",
    "# Indices\n",
    "sixty_percent = int(0.6 * total_len)\n",
    "next_percent = int(0.62 * total_len)\n",
    "\n",
    "# First 60% for training/validation\n",
    "# dataset_60 = Subset(full_dataset, list(range(0, sixty_percent)))\n",
    "\n",
    "# Middle 30% for testing\n",
    "dataset_test = Subset(full_dataset, list(range(sixty_percent, next_percent)))\n",
    "\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9e9901ee-3016-441c-b4fb-fe73225760ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size on Disk: 28.52 MB\n"
     ]
    }
   ],
   "source": [
    "model_size = os.path.getsize(model_path) \n",
    "print(f\"Model Size on Disk: {model_size/ (1e6) :.2f} MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a160bdb4-12cc-46eb-b53c-782c4cb6826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 10/10 [00:30<00:00,  3.03s/batch]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multi-label accuracy: 77.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "threshold = 0.5\n",
    "\n",
    "# Wrap the test_loader with tqdm\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Evaluating\", unit=\"batch\"):\n",
    "        outputs = model(images)                             # shape: [batch_size, 14]\n",
    "        preds = torch.sigmoid(outputs) > threshold          # shape: [batch_size, 14]\n",
    "        labels = labels.bool()                              # convert labels to bool\n",
    "\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.numel()\n",
    "\n",
    "accuracy = (correct / total) * 100\n",
    "print(f\"Multi-label accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "871b4d60-b5ee-4f4d-8e13-f63a5c3ae246",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_trials = 100  # Number of trials\n",
    "\n",
    "# Get a single sample from the test data\n",
    "\n",
    "single_sample, _ = next(iter(test_loader))  \n",
    "single_sample = single_sample[0].unsqueeze(0)  \n",
    "\n",
    "# Warm-up run \n",
    "with torch.no_grad():\n",
    "    model(single_sample)\n",
    "\n",
    "latencies = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_trials):\n",
    "        start_time = time.time()\n",
    "        _ = model(single_sample)\n",
    "        latencies.append(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4cc3a50-76d1-4836-961f-97fa32109c78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference Latency (single sample, median): 133.29 ms\n",
      "Inference Latency (single sample, 95th percentile): 136.45 ms\n",
      "Inference Latency (single sample, 99th percentile): 145.06 ms\n",
      "Inference Throughput (single sample): 7.48 FPS\n"
     ]
    }
   ],
   "source": [
    "print(f\"Inference Latency (single sample, median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
    "print(f\"Inference Latency (single sample, 95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
    "print(f\"Inference Latency (single sample, 99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
    "print(f\"Inference Throughput (single sample): {num_trials/np.sum(latencies):.2f} FPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4c842ee0-ad0c-4f2c-b461-d75bd3a83081",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_batches = 10  # Number of trials\n",
    "\n",
    "# Get a batch from the test data\n",
    "batch_input, _ = next(iter(test_loader))  \n",
    "\n",
    "# Warm-up run \n",
    "with torch.no_grad():\n",
    "    model(batch_input)\n",
    "\n",
    "batch_times = []\n",
    "with torch.no_grad():\n",
    "    for _ in range(num_batches):\n",
    "        start_time = time.time()\n",
    "        _ = model(batch_input)\n",
    "        batch_times.append(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f9ec6183-d88c-410e-b33c-adad77c76392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Throughput: 5.60 FPS\n"
     ]
    }
   ],
   "source": [
    "batch_fps = (batch_input.shape[0] * num_batches) / np.sum(batch_times) \n",
    "print(f\"Batch Throughput: {batch_fps:.2f} FPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9152fc80-7cbc-49ad-abfc-3bc5013fce7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Size on Disk: 28.52 MB\n",
      "Multi-label accuracy: 77.96%\n",
      "Inference Latency (single sample, median): 133.29 ms\n",
      "Inference Latency (single sample, 95th percentile): 136.45 ms\n",
      "Inference Latency (single sample, 99th percentile): 145.06 ms\n",
      "Inference Throughput (single sample): 7.48 FPS\n",
      "Batch Throughput: 5.60 FPS\n"
     ]
    }
   ],
   "source": [
    "print(f\"Model Size on Disk: {model_size/ (1e6) :.2f} MB\")\n",
    "print(f\"Multi-label accuracy: {accuracy:.2f}%\")\n",
    "print(f\"Inference Latency (single sample, median): {np.percentile(latencies, 50) * 1000:.2f} ms\")\n",
    "print(f\"Inference Latency (single sample, 95th percentile): {np.percentile(latencies, 95) * 1000:.2f} ms\")\n",
    "print(f\"Inference Latency (single sample, 99th percentile): {np.percentile(latencies, 99) * 1000:.2f} ms\")\n",
    "print(f\"Inference Throughput (single sample): {num_trials/np.sum(latencies):.2f} FPS\")\n",
    "print(f\"Batch Throughput: {batch_fps:.2f} FPS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f01a410-f45b-4820-9555-a27a0648fad3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
