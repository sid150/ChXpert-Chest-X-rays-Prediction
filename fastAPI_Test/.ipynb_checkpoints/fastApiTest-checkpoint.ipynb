{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77e27d5-9ca0-4438-bd8b-3a0f423e55c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import os\n",
    "\n",
    "print(os.getcwd())\n",
    "image_path = \"fastAPI_Test/test_image.jpeg\"\n",
    "with open(image_path, 'rb') as f:\n",
    "    image_bytes = f.read()\n",
    "encoded_str =  base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "print('\"' + encoded_str + '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f441a983-c784-48f0-adbe-5fabc0777bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import requests\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070ef30-31de-40d0-bb67-31fb8055b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "FASTAPI_URL = \"http://fastapi_server:8000/predict\"\n",
    "payload = {\"image\": encoded_str}\n",
    "num_requests = 100\n",
    "inference_times = []\n",
    "\n",
    "for _ in range(num_requests):\n",
    "    start_time = time.time()\n",
    "    response = requests.post(FASTAPI_URL, json=payload)\n",
    "    end_time = time.time()\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        inference_times.append(end_time - start_time)\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2175339f-d894-46cd-8c79-39f0ca10ee45",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_times = np.array(inference_times)\n",
    "median_time = np.median(inference_times)\n",
    "percentile_95 = np.percentile(inference_times, 95)\n",
    "percentile_99 = np.percentile(inference_times, 99)\n",
    "throughput = num_requests / inference_times.sum()  \n",
    "\n",
    "print(f\"Median inference time: {1000*median_time:.4f} ms\")\n",
    "print(f\"95th percentile: {1000*percentile_95:.4f} ms\")\n",
    "print(f\"99th percentile: {1000*percentile_99:.4f} seconds\")\n",
    "print(f\"Throughput: {throughput:.2f} requests/sec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e664e58-29a5-486f-a792-efbb5c95a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "\n",
    "def send_request(payload):\n",
    "    start_time = time.time()\n",
    "    response = requests.post(FASTAPI_URL, json=payload)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        return end_time - start_time\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}, Response: {response.text}\")\n",
    "        return None\n",
    "\n",
    "def run_concurrent_tests(num_requests, payload, max_workers=10):\n",
    "    inference_times = []\n",
    "    \n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        futures = [executor.submit(send_request, payload) for _ in range(num_requests)]\n",
    "        \n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            result = future.result()\n",
    "            if result is not None:\n",
    "                inference_times.append(result)\n",
    "    \n",
    "    return inference_times\n",
    "\n",
    "num_requests = 1000\n",
    "start_time = time.time()\n",
    "inference_times = run_concurrent_tests(num_requests, payload, max_workers=16)\n",
    "total_time = time.time() - start_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbdc885-a152-4655-a4e8-cf6d4829a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "inference_times = np.array(inference_times)\n",
    "median_time = np.median(inference_times)\n",
    "percentile_95 = np.percentile(inference_times, 95)\n",
    "percentile_99 = np.percentile(inference_times, 99)\n",
    "throughput = num_requests / total_time\n",
    "\n",
    "print(f\"Median inference time: {1000*median_time:.4f} ms\")\n",
    "print(f\"95th percentile: {1000*percentile_95:.4f} ms\")\n",
    "print(f\"99th percentile: {1000*percentile_99:.4f} seconds\")\n",
    "print(f\"Throughput: {throughput:.2f} requests/sec\")\n",
    "     "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
