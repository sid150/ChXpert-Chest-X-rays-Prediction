version: '3.8'
name: persist_block

services:
  minio:
    image: minio/minio
    container_name: minio
    restart: always
    expose:
      - "9000"
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER:     ${MINIO_ROOT_USER}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD}
    healthcheck:
      test: timeout 5s bash -c ':> /dev/tcp/127.0.0.1/9000' || exit 1
      interval: 1s
      timeout: 10s
      retries: 5
    command: server /data --console-address ":9001"
    volumes:
      - /mnt/block/minio_data:/data

  minio-create-bucket:
    image: minio/mc
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set minio http://minio:9000 ${MINIO_ROOT_USER} ${MINIO_ROOT_PASSWORD} &&
      mc mb minio/mlflow-artifacts 2>/dev/null || echo 'mlflow-artifacts exists' &&
      mc mb minio/ray               2>/dev/null || echo 'ray exists'
      "

  postgres:
    image: postgres:latest
    container_name: postgres
    restart: always
    environment:
      POSTGRES_USER:     ${POSTGRES_USER}
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_DB:       ${POSTGRES_DB}
    ports:
      - "5432:5432"
    volumes:
      - /mnt/block/postgres_data:/var/lib/postgresql/data

  mlflow:
    image: ghcr.io/mlflow/mlflow:v2.20.2
    container_name: mlflow
    restart: always
    depends_on:
      - minio
      - postgres
      - minio-create-bucket

    environment:
      AWS_ACCESS_KEY_ID:                      ${AWS_ACCESS_KEY_ID}
      AWS_SECRET_ACCESS_KEY:                  ${AWS_SECRET_ACCESS_KEY}
      MLFLOW_S3_ENDPOINT_URL:                 http://minio:9000
      # multipart upload to avoid big proxy
      MLFLOW_ENABLE_PROXY_MULTIPART_UPLOAD:   "true"
      MLFLOW_MULTIPART_UPLOAD_MINIMUM_FILE_SIZE: "500000000"
      MLFLOW_MULTIPART_UPLOAD_CHUNK_SIZE:        "100000000"

    ports:
      - "8000:8000"

    volumes:
      # gunicorn temp spooling also on big disk
      - /mnt/block/mlflow/tmp:/tmp

    entrypoint:
      - /bin/sh
      - -c
      - |
        pip install psycopg2-binary boto3 && \
        exec mlflow server \
          --backend-store-uri postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres/${POSTGRES_DB} \
          --default-artifact-root s3://mlflow-artifacts/ \
          --host 0.0.0.0 --port 8000 \
          --gunicorn-opts="--timeout 600 --workers 2 --worker-tmp-dir /tmp"
    command: []

  jupyter:
    image: quay.io/jupyter/pytorch-notebook:pytorch-2.5.1
    container_name: jupyter
    restart: always
    shm_size: 8g
    ports:
      - "8888:8888"
    environment:
      - MLFLOW_TRACKING_URI=http://${HOST_IP}:8000/
      - CHEXPERT_DATA_DIR=/mnt/chexpert
      - MLFLOW_HTTP_REQUEST_TIMEOUT=600
    volumes:
      - /home/cc/ChXpert-Chest-X-rays-Prediction:/home/jovyan/ChXpert-Chest-X-rays-Prediction
      - type: bind
        source: /mnt/object
        target: /mnt/chexpert
        read_only: true
    command: >
      bash -c "pip install mlflow && \
                start-notebook.sh --NotebookApp.notebook_dir=/home/jovyan/ChXpert-Chest-X-rays-Prediction"